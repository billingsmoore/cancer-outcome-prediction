{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Patient Outcomes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Breast Cancer is a very serious disease. The possibility of terminal illness is terrifying for patients and their families. As such, an accurate prognosis, a prediction of a case's likely outcome, is extremely important. This project aims to train a supervised learning model to make accurate predictions of breast cancer case outcomes. That is to say, given a list of predictors this model should be able to accurately predict whether or not the case will be fatal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "As we will see below, the optimal prediction accuracy that I am able to achieve on this dataset is $81.1\\%$. This performance remains constant across Logistic Regression, Random Forest, and Support Vector Machine approaches, though the Support Vector Machine is the only model that is able to achieve this accuracy without any significant tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "This dataset was uploaded to Kaggle by Kreesh Rajani and can be found here: \n",
    "https://www.kaggle.com/datasets/kreeshrajani/breast-cancer-survival-dataset\n",
    "\n",
    "Looking at the dataframe head below, we can see that we have 14 possible predictors for our 1 outcome variable, Patient_Status. Patient_Status is a binary variable, bluntly given as (Alive/Dead), which gives us the patient outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Protein1</th>\n",
       "      <th>Protein2</th>\n",
       "      <th>Protein3</th>\n",
       "      <th>Protein4</th>\n",
       "      <th>Tumour_Stage</th>\n",
       "      <th>Histology</th>\n",
       "      <th>ER status</th>\n",
       "      <th>PR status</th>\n",
       "      <th>HER2 status</th>\n",
       "      <th>Surgery_type</th>\n",
       "      <th>Date_of_Surgery</th>\n",
       "      <th>Date_of_Last_Visit</th>\n",
       "      <th>Patient_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.95256</td>\n",
       "      <td>2.15000</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>-0.048340</td>\n",
       "      <td>II</td>\n",
       "      <td>Infiltrating Ductal Carcinoma</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Other</td>\n",
       "      <td>20-May-18</td>\n",
       "      <td>26-Aug-18</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.38020</td>\n",
       "      <td>-0.498030</td>\n",
       "      <td>-0.507320</td>\n",
       "      <td>II</td>\n",
       "      <td>Infiltrating Ductal Carcinoma</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Other</td>\n",
       "      <td>26-Apr-18</td>\n",
       "      <td>25-Jan-19</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>-0.52303</td>\n",
       "      <td>1.76400</td>\n",
       "      <td>-0.370190</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>II</td>\n",
       "      <td>Infiltrating Ductal Carcinoma</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Lumpectomy</td>\n",
       "      <td>24-Aug-18</td>\n",
       "      <td>08-Apr-20</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>-0.87618</td>\n",
       "      <td>0.12943</td>\n",
       "      <td>-0.370380</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>I</td>\n",
       "      <td>Infiltrating Ductal Carcinoma</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Other</td>\n",
       "      <td>16-Nov-18</td>\n",
       "      <td>28-Jul-20</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.22611</td>\n",
       "      <td>1.74910</td>\n",
       "      <td>-0.543970</td>\n",
       "      <td>-0.390210</td>\n",
       "      <td>II</td>\n",
       "      <td>Infiltrating Ductal Carcinoma</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Lumpectomy</td>\n",
       "      <td>12-Dec-18</td>\n",
       "      <td>05-Jan-19</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Protein1  Protein2  Protein3  Protein4 Tumour_Stage  \\\n",
       "0   42  FEMALE   0.95256   2.15000  0.007972 -0.048340           II   \n",
       "1   54  FEMALE   0.00000   1.38020 -0.498030 -0.507320           II   \n",
       "2   63  FEMALE  -0.52303   1.76400 -0.370190  0.010815           II   \n",
       "3   78  FEMALE  -0.87618   0.12943 -0.370380  0.132190            I   \n",
       "4   42  FEMALE   0.22611   1.74910 -0.543970 -0.390210           II   \n",
       "\n",
       "                       Histology ER status PR status HER2 status Surgery_type  \\\n",
       "0  Infiltrating Ductal Carcinoma  Positive  Positive    Negative        Other   \n",
       "1  Infiltrating Ductal Carcinoma  Positive  Positive    Negative        Other   \n",
       "2  Infiltrating Ductal Carcinoma  Positive  Positive    Negative   Lumpectomy   \n",
       "3  Infiltrating Ductal Carcinoma  Positive  Positive    Negative        Other   \n",
       "4  Infiltrating Ductal Carcinoma  Positive  Positive    Positive   Lumpectomy   \n",
       "\n",
       "  Date_of_Surgery Date_of_Last_Visit Patient_Status  \n",
       "0       20-May-18          26-Aug-18          Alive  \n",
       "1       26-Apr-18          25-Jan-19           Dead  \n",
       "2       24-Aug-18          08-Apr-20          Alive  \n",
       "3       16-Nov-18          28-Jul-20          Alive  \n",
       "4       12-Dec-18          05-Jan-19          Alive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('breast_cancer_survival.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see a summary of the numerical data. We have 334 total rows, there are only NA values in two columns: Date_of_Last_Visit and Patient_Status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age    Protein1    Protein2    Protein3    Protein4\n",
      "count  334.000000  334.000000  334.000000  334.000000  334.000000\n",
      "mean    58.886228   -0.029991    0.946896   -0.090204    0.009819\n",
      "std     12.961212    0.563588    0.911637    0.585175    0.629055\n",
      "min     29.000000   -2.340900   -0.978730   -1.627400   -2.025500\n",
      "25%     49.000000   -0.358888    0.362173   -0.513748   -0.377090\n",
      "50%     58.000000    0.006129    0.992805   -0.173180    0.041768\n",
      "75%     68.000000    0.343598    1.627900    0.278353    0.425630\n",
      "max     90.000000    1.593600    3.402200    2.193400    1.629900\n",
      "\n",
      "NA counts:\n",
      "Age                    0\n",
      "Gender                 0\n",
      "Protein1               0\n",
      "Protein2               0\n",
      "Protein3               0\n",
      "Protein4               0\n",
      "Tumour_Stage           0\n",
      "Histology              0\n",
      "ER status              0\n",
      "PR status              0\n",
      "HER2 status            0\n",
      "Surgery_type           0\n",
      "Date_of_Surgery        0\n",
      "Date_of_Last_Visit    17\n",
      "Patient_Status        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n",
    "\n",
    "print('\\nNA counts:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data\n",
    "\n",
    "The NA values for Patient_Status are especially problematic but there are not very many of them, so we will drop the NA value rows. We can see below that we end up with 317 rows so we have only lost about $5\\%$ of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age    Protein1    Protein2    Protein3    Protein4\n",
      "count  317.000000  317.000000  317.000000  317.000000  317.000000\n",
      "mean    58.725552   -0.027232    0.949557   -0.095104    0.006713\n",
      "std     12.827374    0.543858    0.906153    0.589027    0.625965\n",
      "min     29.000000   -2.144600   -0.978730   -1.627400   -2.025500\n",
      "25%     49.000000   -0.350600    0.368840   -0.531360   -0.382240\n",
      "50%     58.000000    0.005649    0.997130   -0.193040    0.038522\n",
      "75%     67.000000    0.336260    1.612000    0.251210    0.436250\n",
      "max     90.000000    1.593600    3.402200    2.193400    1.629900\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few columns have spaces in their column names which could cause some syntax problems later on so I will rename those to remove the space. They all end in the word 'status' so I will drop that as well. Once that is done, we turn our attention to our non-numeric data. \n",
    "\n",
    "In the Gender column, I will map 'FEMALE' to 0 and 'MALE' to 1. For ER, PR, and HER2 I will map 'Negative' to 0 and 'Positive' to 1. For the Tumour_Stage variable, I will map each roman numeral to its corresponding integer. The 'Histology' column has three possible values: 'Infiltrating Ductal Carcinoma', 'Infiltrating Lobular Carcinoma', and 'Mucinous Carcinoma' which I will map to 0, 1, and 2 respectively. The 'Surgery_type' columns has the following values: 'Other', 'Lumpectomy', 'Modified Radical Mastectomy', and 'Simple Mastectomy' which I will map to 0, 1, 2, and 3 respectively.\n",
    "\n",
    "Under the assumption that particular surgery dates or particular appointment dates have no meaningful impact (i.e. meeting with one's doctor on a Tuesday does not increase one's chances of survival), but may introduce additional noise, we will drop these columns. It is entirely possible that this assumption is mistaken and for an applied study a domain expert should be consulted.\n",
    "\n",
    "Finally, our target variable 'Patient_Status' has two values: 'Dead' and 'Alive' which I will map to 0, and 1 respectively.\n",
    "\n",
    "Our final dimensions then are 317 rows with 12 predictors for our target variable.\n",
    "\n",
    "Our new, clean dataframe looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Protein1</th>\n",
       "      <th>Protein2</th>\n",
       "      <th>Protein3</th>\n",
       "      <th>Protein4</th>\n",
       "      <th>Tumour_Stage</th>\n",
       "      <th>Histology</th>\n",
       "      <th>ER</th>\n",
       "      <th>PR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>Surgery_type</th>\n",
       "      <th>Patient_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95256</td>\n",
       "      <td>2.15000</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>-0.048340</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.38020</td>\n",
       "      <td>-0.498030</td>\n",
       "      <td>-0.507320</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.52303</td>\n",
       "      <td>1.76400</td>\n",
       "      <td>-0.370190</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.87618</td>\n",
       "      <td>0.12943</td>\n",
       "      <td>-0.370380</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22611</td>\n",
       "      <td>1.74910</td>\n",
       "      <td>-0.543970</td>\n",
       "      <td>-0.390210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Protein1  Protein2  Protein3  Protein4  Tumour_Stage  \\\n",
       "0   42       0   0.95256   2.15000  0.007972 -0.048340             2   \n",
       "1   54       0   0.00000   1.38020 -0.498030 -0.507320             2   \n",
       "2   63       0  -0.52303   1.76400 -0.370190  0.010815             2   \n",
       "3   78       0  -0.87618   0.12943 -0.370380  0.132190             1   \n",
       "4   42       0   0.22611   1.74910 -0.543970 -0.390210             2   \n",
       "\n",
       "   Histology  ER  PR  HER2  Surgery_type  Patient_Status  \n",
       "0          0   1   1     0             0               1  \n",
       "1          0   1   1     0             0               0  \n",
       "2          0   1   1     0             1               1  \n",
       "3          0   1   1     0             0               1  \n",
       "4          0   1   1     1             1               1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'ER status': 'ER', 'PR status': 'PR', 'HER2 status': 'HER2'})\n",
    "\n",
    "df['Gender'] = df['Gender'].map({'FEMALE' : 0, 'MALE' : 1})\n",
    "\n",
    "df['ER'] = df['ER'].map({'Negative' : 0, 'Positive' : 1})\n",
    "\n",
    "df['PR'] = df['PR'].map({'Negative' : 0, 'Positive' : 1})\n",
    "\n",
    "df['HER2'] = df['HER2'].map({'Negative' : 0, 'Positive' : 1})\n",
    "\n",
    "df['Tumour_Stage'] = df['Tumour_Stage'].map({'I' : 1, 'II' : 2, 'III': 3, 'IV': 4})\n",
    "\n",
    "df['Histology'] = df['Histology'].map({'Infiltrating Ductal Carcinoma' : 0, 'Infiltrating Lobular Carcinoma' : 1, 'Mucinous Carcinoma' : 2})\n",
    "\n",
    "df['Surgery_type'] = df['Surgery_type'].map({'Other' : 0, 'Lumpectomy' : 1, 'Modified Radical Mastectomy' : 2,'Simple Mastectomy' : 3})\n",
    "\n",
    "df = df.drop(columns=['Date_of_Surgery', 'Date_of_Last_Visit'], axis=1)\n",
    "\n",
    "df['Patient_Status'] = df['Patient_Status'].map({'Dead' : 0, 'Alive' : 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data\n",
    "\n",
    "Now that our data is clean, we can split it for training and testing. I played around a bit with test and training sizes and with this dataset it seems like we get the best results when test size is relatively large. This makes sense, we don't want to be testing on a small sample. Thus, I've set the test size here to 70% of the data. For reproducibility, I've set random_state to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:,:-1]\n",
    "\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.7, random_state=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Now that our training and testing data is split we can start our modeling process. Because this problem has a binary target value, this is a classification problem. Below we see a first pass at a logistic regression model using all possible predictors. The results are not impressive but not hopeless. This may point to a possible issue in our choice (or lack thereof) of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of first Logistic Regression model: 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "reg_mod = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "y_pred = reg_mod.predict(x_test)\n",
    "\n",
    "print('Accuracy of first Logistic Regression model: ' + str(round(accuracy_score(y_pred, y_test),3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "\n",
    "Sci-Kit Learn provides a handy tool for feature selection. The SequentialFeatureSelector will perform forward or backward selection and return the optimal features given a particular number of features to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age']\n",
      "['Age' 'Gender']\n",
      "['Age' 'Gender' 'Protein2']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3' 'Protein4']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3' 'Protein4' 'Tumour_Stage']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3' 'Protein4' 'Tumour_Stage'\n",
      " 'Histology']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3' 'Protein4' 'Tumour_Stage'\n",
      " 'Histology' 'HER2']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3' 'Protein4' 'Tumour_Stage'\n",
      " 'Histology' 'ER' 'HER2']\n",
      "['Age' 'Gender' 'Protein1' 'Protein2' 'Protein3' 'Protein4' 'Tumour_Stage'\n",
      " 'Histology' 'ER' 'PR' 'HER2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "feature_names = np.array(x_train.columns)\n",
    "\n",
    "for i in range(1,12):\n",
    "    log_reg = LogisticRegression()\n",
    "    forward_selector = SequentialFeatureSelector(log_reg, n_features_to_select=i, direction='forward').fit(x_train,y_train)\n",
    "    features = feature_names[forward_selector.get_support()]\n",
    "    print(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I trained a series of models using each set of features. We can see that accuracy goes down beyond 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 features, accuracy is 0.8108108108108109\n",
      "With 2 features, accuracy is 0.8108108108108109\n",
      "With 3 features, accuracy is 0.8108108108108109\n",
      "With 4 features, accuracy is 0.8063063063063063\n",
      "With 5 features, accuracy is 0.8063063063063063\n",
      "With 6 features, accuracy is 0.8063063063063063\n",
      "With 7 features, accuracy is 0.8018018018018018\n",
      "With 8 features, accuracy is 0.8063063063063063\n",
      "With 9 features, accuracy is 0.8063063063063063\n",
      "With 10 features, accuracy is 0.8063063063063063\n",
      "With 11 features, accuracy is 0.8063063063063063\n"
     ]
    }
   ],
   "source": [
    "nfeatures = 1\n",
    "\n",
    "x = x_train[['Age']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein2']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology', 'HER2']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology', 'HER2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology', 'ER', 'HER2']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology', 'ER', 'HER2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1\n",
    "\n",
    "x = x_train[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology', 'ER', 'PR', 'HER2']]\n",
    "model = LogisticRegression().fit(x, y_train)\n",
    "y_pred = model.predict(x_test[['Age', 'Gender', 'Protein1', 'Protein2', 'Protein3', 'Protein4', 'Tumour_Stage','Histology', 'ER', 'PR', 'HER2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('With ' + str(nfeatures) + ' features, accuracy is '+ str(score))\n",
    "nfeatures += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what set of features backward selection recommends. We'll assume that 3 features is the sweet spot. We see below that backward selection ends up agreeing that Age, Gender, and Protein2 are our best predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Protein4' 'Tumour_Stage' 'Histology']\n"
     ]
    }
   ],
   "source": [
    "backward_selector = SequentialFeatureSelector(log_reg, n_features_to_select=3, direction='backward').fit(x_train,y_train)\n",
    "features = feature_names[backward_selector.get_support()]\n",
    "print(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our two final logistic regression model here each use 3 features, 'Age', 'Gender', and 'Protein2' for the forward-selected model, 'Protein4','Tumour_Stage', and 'Histology' for the backward-selected model. As we can see below, both have an accuracy of $81.1\\%$ Which is better than where we started but still not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final forward-selected logistic regression model is: 0.811\n",
      "Accuracy of final backward-selected logistic regression model is: 0.811\n"
     ]
    }
   ],
   "source": [
    "x = x_train[['Age', 'Gender', 'Protein2']]\n",
    "log_mod = LogisticRegression().fit(x, y_train)\n",
    "y_pred = log_mod.predict(x_test[['Age', 'Gender', 'Protein2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of final forward-selected logistic regression model is: ' + str(round(score,3)))\n",
    "\n",
    "x = x_train[['Protein4','Tumour_Stage','Histology']]\n",
    "final_log_mod = LogisticRegression().fit(x, y_train)\n",
    "y_pred = final_log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of final backward-selected logistic regression model is: ' + str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Gender Parameter\n",
    "\n",
    "It is interesting that 'Gender' is such an important predictor. It's worth exploring further why that is. Because I've set 'Dead' to 0 and 'Alive' to 1 in the 'Patient_Status' column, the mean of that column is also the survival rate. Below I've separated female and male patients and calculated their survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female survival rate: 0.805111821086262\n",
      "Male survival rate: 0.75\n"
     ]
    }
   ],
   "source": [
    "females = df.loc[df['Gender'] == 0]\n",
    "\n",
    "print('Female survival rate: ' + str(females['Patient_Status'].mean()))\n",
    "\n",
    "males = df.loc[df['Gender'] == 1]\n",
    "\n",
    "print('Male survival rate: ' + str(males['Patient_Status'].mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that female survival rate is notably higher than the male survival rate. We might think that this is due to females being more likely to be screened or more likely to be diagnosed early for some other reason but we would have to consult a domain expert to be certain. For now, let's try looking at just the female patients and see what that does to our selection of predictors and subsequent accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = females.drop(columns=['Gender'])\n",
    "\n",
    "fx = females.iloc[:,:-1]\n",
    "\n",
    "fy = females.iloc[:,-1]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is even smaller now, I will increase our test size to 85% of the data to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_train, fx_test, fy_train, fy_test = train_test_split(fx, fy, test_size=.85, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of full Logistic Regression model: 0.801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reg_mod = LogisticRegression().fit(fx_train, fy_train)\n",
    "\n",
    "y_pred = reg_mod.predict(fx_test)\n",
    "\n",
    "print('Accuracy of full Logistic Regression model: ' + str(round(accuracy_score(y_pred, fy_test),3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the full model, the model using all predictors, seems to improve! That's promising. Let's try selecting our best predictors then. We'll keep assuming that 3 predictors is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age' 'Protein1' 'Protein3']\n",
      "['ER' 'PR' 'HER2']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(fx_train.columns)\n",
    "\n",
    "forward_selector = SequentialFeatureSelector(log_reg, n_features_to_select=3, direction='forward').fit(fx_train,fy_train)\n",
    "features = feature_names[forward_selector.get_support()]\n",
    "print(features)\n",
    "\n",
    "backward_selector = SequentialFeatureSelector(log_reg, n_features_to_select=3, direction='backward').fit(fx_train,fy_train)\n",
    "features = feature_names[backward_selector.get_support()]\n",
    "print(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a new set of features: 'Age', 'Protein1', and 'Protein3' from forward-selection; 'PR', 'HER2', and 'Surgery_type' from backward-selection. Below, I've trained two models using these predictors. We can see that the forward-selected model appears to perform now better than the full model but the backward selected model is slightly improved, though interestingly, it still performs worse than the model that was trained on data from both 'Gender' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of forward-selected logistic regression model is: 0.801\n",
      "Accuracy of backward-selected logistic regression model is: 0.809\n"
     ]
    }
   ],
   "source": [
    "fx =fx_train[['Age','Protein1','Protein3']]\n",
    "log_mod = LogisticRegression().fit(fx, fy_train)\n",
    "y_pred = log_mod.predict(fx_test[['Age','Protein1','Protein3']])\n",
    "score = accuracy_score(y_pred, fy_test)\n",
    "print('Accuracy of forward-selected logistic regression model is: ' + str(round(score,3)))\n",
    "\n",
    "fx = fx_train[['PR','HER2', 'Surgery_type']]\n",
    "log_mod = LogisticRegression().fit(fx, fy_train)\n",
    "y_pred = log_mod.predict(fx_test[['PR', 'HER2', 'Surgery_type']])\n",
    "score = accuracy_score(y_pred, fy_test)\n",
    "print('Accuracy of backward-selected logistic regression model is: ' + str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solver Selection\n",
    "\n",
    "So, our best prediction model, the backward-selected model trained on the full data set, uses 3 predictors: 'Protein4', 'Tumour_Stage', and 'Histology'. Up until now, I've been using LogisticRegression's default solver, 'lbgs'. It's worth confirming that this solver in fact produces the best results. Below, using these same predictors, I've trained a series of models using the other solver options. We can see that there is no substantial difference in predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liblinear model is: 0.811\n",
      "Accuracy of newton-cg model is: 0.811\n",
      "Accuracy of newton-cholesky model is: 0.811\n",
      "Accuracy of sag model is: 0.811\n",
      "Accuracy of saga model is: 0.811\n"
     ]
    }
   ],
   "source": [
    "x = x_train[['Protein4','Tumour_Stage','Histology']]\n",
    "log_mod = LogisticRegression(solver='liblinear').fit(x, y_train)\n",
    "y_pred = log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of liblinear model is: ' + str(round(score,3)))\n",
    "\n",
    "log_mod = LogisticRegression(solver='newton-cg').fit(x, y_train)\n",
    "y_pred = log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of newton-cg model is: ' + str(round(score,3)))\n",
    "\n",
    "log_mod = LogisticRegression(solver='newton-cholesky').fit(x, y_train)\n",
    "y_pred = log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of newton-cholesky model is: ' + str(round(score,3)))\n",
    "\n",
    "log_mod = LogisticRegression(solver='sag').fit(x, y_train)\n",
    "y_pred = log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of sag model is: ' + str(round(score,3)))\n",
    "\n",
    "log_mod = LogisticRegression(solver='saga').fit(x, y_train)\n",
    "y_pred = log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of saga model is: ' + str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in the final lecture of class, though, that Logistic Regression is frequently outperformed by other approaches. Random Forest, in particular, seems to outperform our other approaches. Let's see if that is the case here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "To begin, I trained a RandomForestClassifier, again from Sci-Kit Learn, on the full data with all of the predictors. For reproducibility, I've set the random_state to 0. We end up with an accuracy of $80.6\\%$. This is better than the full model for Logistic Regression, though not as good as our final model from the Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for_mod = RandomForestClassifier(random_state=0).fit(x_train, y_train)\n",
    "\n",
    "y_pred = for_mod.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print('Random Forest accuracy: ' +str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "\n",
    "Next, I've run the SequentialFeatureSelector both forward and backward to select our optimal features. As we can see below, the forward selector gives us 'Gender', 'Tumour_Stage', and 'ER', while the backward selector gives us 'Tumour_Stage', 'PR', and 'HER2'. Note that this differs from the features selected for the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender' 'Tumour_Stage' 'ER']\n",
      "['Age' 'Protein4' 'Surgery_type']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(x_train.columns)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "forward_selector = SequentialFeatureSelector(rfc, n_features_to_select=3, direction='forward').fit(x_train,y_train)\n",
    "features = feature_names[forward_selector.get_support()]\n",
    "print(features)\n",
    "\n",
    "backward_selector = SequentialFeatureSelector(rfc, n_features_to_select=3, direction='backward').fit(x_train,y_train)\n",
    "features = feature_names[backward_selector.get_support()]\n",
    "print(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I've trained to RandomForestClassifiers using only the three predictors selected from the above two lists. This does improve our accuracy, however, we end up with the same predictive accuracy, $81.1\\%$ as the best Logistic Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the forward-selected model is 0.811\n",
      "Accuracy of the backward-selected model is 0.811\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for_mod = RandomForestClassifier().fit(x_train[['Gender', 'Tumour_Stage', 'ER']], y_train)\n",
    "y_pred = for_mod.predict(x_test[['Gender', 'Tumour_Stage', 'ER']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of the forward-selected model is ' + str(round(score,3)))\n",
    "\n",
    "for_mod = RandomForestClassifier().fit(x_train[['Tumour_Stage', 'PR', 'HER2']], y_train)\n",
    "y_pred = for_mod.predict(x_test[['Tumour_Stage', 'PR', 'HER2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of the backward-selected model is ' + str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "\n",
    "Features are not the only parameters to consider here, however, as the RandomForestClassifier has a number of hyperparameters. Below, I've used GridSearchCV to find the optimal hyperparameters. I've used the full model, rather than just the predictors selected previously. We find that the best set of parameters is {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'warm_start': True}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "param_grid = {'criterion':['gini', 'entropy', 'log_loss'], \n",
    "              'max_depth': [1,2,3,4,5],\n",
    "              'max_features': ['sqrt', 'log2'],\n",
    "              'bootstrap': [True, False],\n",
    "              'warm_start': [True,False],\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid).fit(x_train,y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Random Forest Models\n",
    "\n",
    "Training a RandomForestClassifier on the full data we get an accuracy of $81.1\\%$ which is as good as our previous models that were restricted to our selected predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Random Forest accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "for_mod = RandomForestClassifier(bootstrap=True, criterion='gini', max_depth=1, max_features='sqrt', warm_start=True, random_state=0).fit(x_train, y_train)\n",
    "y_pred = for_mod.predict(x_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Best Parameter Random Forest accuracy: ' +str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these parameters on the restricted sets of predictors yields the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Forward-Selected Random Forest accuracy: 0.811\n",
      "Best Parameter Backward-Selected Random Forest accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "for_mod = RandomForestClassifier(bootstrap=True, criterion='gini', max_depth=1, max_features='sqrt', warm_start=True, random_state=0).fit(x_train[['Gender', 'Tumour_Stage', 'ER']], y_train)\n",
    "y_pred = for_mod.predict(x_test[['Gender', 'Tumour_Stage', 'ER']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Best Parameter Forward-Selected Random Forest accuracy: ' +str(round(score,3)))\n",
    "\n",
    "for_mod = RandomForestClassifier(bootstrap=True, criterion='gini', max_depth=1, max_features='sqrt', warm_start=True, random_state=0).fit(x_train[['Tumour_Stage', 'PR', 'HER2']], y_train)\n",
    "y_pred = for_mod.predict(x_test[['Tumour_Stage', 'PR', 'HER2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Best Parameter Backward-Selected Random Forest accuracy: ' +str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be safe, let's try a GridSearch for the 'best' predictors. Below, we can see that we do in fact end up with the same set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward selection best parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'warm_start': True}\n",
      "Backward selection best parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid).fit(x_train[['Gender', 'Tumour_Stage', 'ER']],y_train)\n",
    "print('Forward selection best parameters: ' + str(grid.best_params_))\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid).fit(x_train[['Tumour_Stage', 'PR', 'HER2']],y_train)\n",
    "print('Backward selection best parameters: ' + str(grid.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be extra sure that this is the best that we can do with prediction accuracy, we'll try one more approach.\n",
    "\n",
    "### Support Vector Machine\n",
    "\n",
    "Once again, let's try a full model to see what we get with minimal effort. Below, I've trained a Linear Support Vector Machine on all predictors. We can see that right away performance already rivals the best results of the Regression and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC().fit(x_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(x_test)\n",
    "\n",
    "svc_score = round(accuracy_score(y_pred, y_test),3)\n",
    "\n",
    "print(svc_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "\n",
    "Next, let's try to find what the ideal predictors are for our SVC model. Again, I've implemented both forward and backward selection below. To keep things computationally feasible, we'll stick with 3 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age' 'Gender' 'Protein4']\n",
      "['PR' 'HER2' 'Surgery_type']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(x_train.columns)\n",
    "\n",
    "svc = LinearSVC()\n",
    "\n",
    "forward_selector = SequentialFeatureSelector(svc, n_features_to_select=3, direction='forward').fit(x_train,y_train)\n",
    "features = feature_names[forward_selector.get_support()]\n",
    "print(features)\n",
    "\n",
    "backward_selector = SequentialFeatureSelector(svc, n_features_to_select=3, direction='backward').fit(x_train,y_train)\n",
    "features = feature_names[backward_selector.get_support()]\n",
    "print(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that forward selection gives us 'Age', 'Protein1', and 'Protein3'. Backward selection gives us 'ER', 'PR', and 'HER2'. Below I've trained two SVC models using these two sets of predictors. We can see that the performance for both is $81.1\\%$ again. We get no additional benefit from using additional predictors, much as we saw with the Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the forward-selected model is 0.811\n",
      "Accuracy of the backward-selected model is 0.811\n"
     ]
    }
   ],
   "source": [
    "forward_svc = LinearSVC().fit(x_train[['Age', 'Protein1', 'Protein3']], y_train)\n",
    "y_pred = forward_svc.predict(x_test[['Age', 'Protein1', 'Protein3']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of the forward-selected model is ' + str(round(score,3)))\n",
    "\n",
    "backward_svc = LinearSVC().fit(x_train[['ER', 'PR', 'HER2']], y_train)\n",
    "y_pred = backward_svc.predict(x_test[['ER', 'PR', 'HER2']])\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy of the backward-selected model is ' + str(round(score,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Turning\n",
    "\n",
    "Now, let's confirm that we have optimised our hyperparameters. I've again implemented GridSearchCV to get the best set of hyperparameters. Below, we see that the ideal parameters are {'class_weight': None, 'dual': True, 'fit_intercept': True, 'loss': 'hinge', 'multi_class': 'crammer_singer', 'penalty': 'l1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'dual': True, 'fit_intercept': True, 'loss': 'hinge', 'multi_class': 'crammer_singer', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'dual': [True, False],\n",
    "              'multi_class': ['ovr', 'crammer_singer'],\n",
    "              'fit_intercept': [True, False],\n",
    "              'class_weight': [None, 'balanced']\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(LinearSVC(), param_grid=param_grid).fit(x_train,y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal SVM Model\n",
    "\n",
    "Now, let's train a model using those parameters and the predictors from the backward selected model. We see, though, that performance has not improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811\n"
     ]
    }
   ],
   "source": [
    "opt_svc = LinearSVC(dual=True, fit_intercept=True, loss='hinge', multi_class='crammer_singer', penalty='l1').fit(x_train[['ER', 'PR', 'HER2']], y_train)\n",
    "\n",
    "y_pred = opt_svc.predict(x_test[['ER', 'PR', 'HER2']])\n",
    "\n",
    "opt_score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print(opt_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our models top out at about $81.1\\%$ accuracy, but there is one more trick we can try to improve our accuracy.\n",
    "\n",
    "### Ensembling\n",
    "\n",
    "Obviously, the Random Forest Model on its own is an ensemble method, but what if we make an ensemble out of the three optimized models from Logistic Regression, Random Forest, and Support Vector Machine methods.\n",
    "\n",
    "Below, I've implemented a voting system. Since all of the models perfrom about equally well, there is no need to weight any of them.\n",
    "\n",
    "I've also implemented several other ensembles. The first gives a prediction of 1 if any model gives a prediction of 1. The second gives a predicition of 0 if any of the models gives a prediction of 0. The third gives a prediction of 1 only if all of the models give a prediction of 1. The fourth gives a prediction of 0 only if all of the models give a prediction of 0.\n",
    "\n",
    "Alas, we get the same over-all accuracy from each of the ensembles as the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Voting: 0.811\n",
      "If any are 1: 0.811\n",
      "If any are 0: 0.811\n",
      "Unanimous 1: 0.811\n",
      "Unanimous 0: 0.811\n"
     ]
    }
   ],
   "source": [
    "svc_pred = opt_svc.predict(x_test[['ER', 'PR', 'HER2']])\n",
    "rf_pred = for_mod.predict(x_test[['Tumour_Stage', 'PR', 'HER2']])\n",
    "lr_pred = log_mod.predict(x_test[['Protein4','Tumour_Stage','Histology']])\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# unweighted voting\n",
    "for i in range(len(svc_pred)):\n",
    "    mean = (svc_pred[i] + rf_pred[i] + lr_pred[i]) / 3\n",
    "    if mean > .6:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    y_pred.append(pred)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('Unweighted Voting: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 1 or rf_pred[i] == 1 or lr_pred[i] == 1:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('If any are 1: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 0 or rf_pred[i] == 0 or lr_pred[i] == 0:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('If any are 0: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 1 and rf_pred[i] == 1 and lr_pred[i] == 1:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('Unanimous 1: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 0 and rf_pred[i] == 0 and lr_pred[i] == 0:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('Unanimous 0: ' + str(score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unoptimized Ensemble\n",
    "\n",
    "These results are dissappointing but their consistency seems to point to an upperbound. It is possible that we are hitting a wall because of overfitting. Let's try creating the same ensembles but with unoptimized models.\n",
    "\n",
    "Below I've reimplemented the same ensembles but using the default settings for SVC, Random Forest, and Logistic Regression on the full data with no feature selection. \n",
    "\n",
    "We can see that this does not improve our modeling efforts though. Perhaps unsurprisingly, the unoptimized models perform worse than our optimized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized SVC: 0.811\n",
      "Unoptimized Random Forest: 0.793\n",
      "Unoptimized Regression: 0.797\n",
      "Unweighted Voting: 0.806\n",
      "If any are 1: 0.811\n",
      "If any are 0: 0.784\n",
      "Unanimous 1: 0.784\n",
      "Unanimous 0: 0.811\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC().fit(x_train, y_train)\n",
    "rf = RandomForestClassifier().fit(x_train, y_train)\n",
    "lr = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "svc_pred = svc.predict(x_test)\n",
    "rf_pred = rf.predict(x_test)\n",
    "lr_pred = lr.predict(x_test)\n",
    "\n",
    "svc_score = round(accuracy_score(svc_pred, y_test),3)\n",
    "rf_score = round(accuracy_score(rf_pred, y_test),3)\n",
    "lr_score = round(accuracy_score(lr_pred, y_test), 3)\n",
    "\n",
    "print('Unoptimized SVC: ' + str(svc_score))\n",
    "print('Unoptimized Random Forest: ' + str(rf_score))\n",
    "print('Unoptimized Regression: ' + str(lr_score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# unweighted voting\n",
    "for i in range(len(svc_pred)):\n",
    "    mean = (svc_pred[i] + rf_pred[i] + lr_pred[i]) / 3\n",
    "    if mean > .6:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    y_pred.append(pred)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('Unweighted Voting: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 1 or rf_pred[i] == 1 or lr_pred[i] == 1:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('If any are 1: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 0 or rf_pred[i] == 0 or lr_pred[i] == 0:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('If any are 0: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 1 and rf_pred[i] == 1 and lr_pred[i] == 1:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('Unanimous 1: ' + str(score))\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(svc_pred)):\n",
    "    if svc_pred[i] == 0 and rf_pred[i] == 0 and lr_pred[i] == 0:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "score = round(accuracy_score(y_pred, y_test), 3)\n",
    "\n",
    "print('Unanimous 0: ' + str(score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Over all, we are only able to achieve an accuracy of $81.1\\%$. However, that does not mean that these models are interchangeable. As we saw above, achieving this accuracy with the Logistic Regression approach required a great deal more work. The other two approaches achieved better results with a minimum amount of effort. The Support Vector Machine in particular achieved the apparently optimal result on the first pass.\n",
    "\n",
    "Accuracy is not the only metric for models, as well. Let's take a look at the precision and recall of our best performing models. We can see below that the models are all roughly equal in these respects as well, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Precision: 0.983\n",
      "Logistic Regression Recall: 0.808\n",
      "Random Forest Precision: 0.972\n",
      "Random Forest Recall: 0.81\n",
      "SVC Precision: 1.0\n",
      "SVC Recall: 0.811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print('Logistic Regression Precision: ' + str(round(precision_score(lr_pred, y_test), 3)))\n",
    "print('Logistic Regression Recall: ' + str(round(recall_score(lr_pred, y_test), 3)))\n",
    "\n",
    "print('Random Forest Precision: ' + str(round(precision_score(rf_pred, y_test), 3)))\n",
    "print('Random Forest Recall: ' + str(round(recall_score(rf_pred, y_test), 3)))\n",
    "\n",
    "print('SVC Precision: ' + str(round(precision_score(svc_pred, y_test), 3)))\n",
    "print('SVC Recall: ' + str(round(recall_score(svc_pred, y_test), 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it then. At least with this dataset, it seems that %81.1\\%$ is our magic number. There is not a supervised modeling method, set of predictors, or set of hyperparameters than can help us improve. It comes down, then, to what the needs of the project are here. Do we prefer to have less coding work for our scientists? Do we need to minimize computational costs? Maybe we're most interested in how quickly predictions can be made. These are all important considerations that could be applied from here to further narrow down the ideal modeling approach for an application of this project to a larger dataset.\n",
    "\n",
    "Some possible explanations for this relatively poor performance may be that this dataset is simply too small. It is also possible that this dataset does not contain some key parameters. A domain expert would need to be consulted to ensure that all of the important information is included. Additionally, the data as provided may not have been sufficiently accurately measured. That is, the data as provided may just be too noisy for accurate prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
